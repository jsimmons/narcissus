#version 460

#extension GL_GOOGLE_include_directive : require

#extension GL_EXT_buffer_reference : require
#extension GL_EXT_buffer_reference2 : require
#extension GL_EXT_scalar_block_layout : require
#extension GL_EXT_control_flow_attributes : require

#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_shuffle_relative: enable
#extension GL_KHR_shader_subgroup_vote : require

#include "radix_sort.h"

#include "draw_2d.h"
#include "indirect.h"

layout (constant_id = 0) const uint SUBGROUP_SIZE = 64;

const uint NUM_SUBGROUPS = RADIX_WGP_SIZE / SUBGROUP_SIZE;

layout(buffer_reference, std430, buffer_reference_align = 4) readonly buffer SpineRef {
    uint values[];
};

layout(buffer_reference, std430, buffer_reference_align = 4) buffer ValuesRef {
    uint values[];
};

struct RadixSortDownsweepConstants {
    uint shift;
    uint _pad;
    CountRef count_buffer;
    SpineRef spine_buffer;
    ValuesRef src_buffer;
    ValuesRef dst_buffer;
};

layout(std430, push_constant) uniform RadixSortDownsweepConstantsBlock {
    RadixSortDownsweepConstants constants;
};

shared uint spine[RADIX_DIGITS];
shared uint match_masks[NUM_SUBGROUPS][RADIX_DIGITS];

layout (local_size_x = RADIX_WGP_SIZE, local_size_y = 1, local_size_z = 1) in;

void main() {
    const uint local_id = gl_SubgroupID * gl_SubgroupSize + gl_SubgroupInvocationID;

    const uint shift = constants.shift;
    const uint count = constants.count_buffer.value;
    const uint wgp_count = (count + (RADIX_ITEMS_PER_WGP - 1)) / RADIX_ITEMS_PER_WGP;

    // Gather from spine.
    spine[local_id] = constants.spine_buffer.values[(local_id * wgp_count) + gl_WorkGroupID.x];

    const bool needs_bounds_check = gl_WorkGroupID.x == wgp_count - 1;

    if (needs_bounds_check) {
        for (uint i = 0; i < RADIX_ITEMS_PER_INVOCATION; i++) {
            const uint base = gl_WorkGroupID.x * RADIX_ITEMS_PER_WGP + i * RADIX_DIGITS;

            if (base >= count)
                break;

            // Clear shared memory and load values from src buffer.
            for (uint j = 0; j < NUM_SUBGROUPS; j++) {
                match_masks[j][local_id] = 0;
            }

            barrier();

            const uint global_id = base + local_id;
            const uint value = global_id < count ? constants.src_buffer.values[global_id] : 0xffffffff;
            const uint digit = (value >> shift) & RADIX_MASK;
            atomicOr(match_masks[gl_SubgroupID][digit], 1 << gl_SubgroupInvocationID);

            barrier();

            uint peer_scan = 0;
            for (uint i = 0; i < gl_NumSubgroups; i++) {
                if (i < gl_SubgroupID) {
                    peer_scan += bitCount(match_masks[i][digit]);
                }
            }
            peer_scan += bitCount(match_masks[gl_SubgroupID][digit] & gl_SubgroupLtMask.x);

            if (global_id < count) {
                constants.dst_buffer.values[spine[digit] + peer_scan] = value;
            }

            barrier();

            // Increment the spine with the counts for the workgroup we just wrote out.
            for (uint i = 0; i < NUM_SUBGROUPS; i++) {
                atomicAdd(spine[local_id], bitCount(match_masks[i][local_id]));
            }
        }
    } else {
        for (uint i = 0; i < RADIX_ITEMS_PER_INVOCATION; i++) {
            // Clear shared memory and load values from src buffer.
            for (uint j = 0; j < NUM_SUBGROUPS; j++) {
                match_masks[j][local_id] = 0;
            }

            barrier();

            const uint global_id = gl_WorkGroupID.x * RADIX_ITEMS_PER_WGP + i * RADIX_DIGITS + local_id;
            const uint value = constants.src_buffer.values[global_id];
            const uint digit = (value >> shift) & RADIX_MASK;
            atomicOr(match_masks[gl_SubgroupID][digit], 1 << gl_SubgroupInvocationID);

            barrier();

            uint peer_scan = 0;
            for (uint i = 0; i < gl_NumSubgroups; i++) {
                if (i < gl_SubgroupID) {
                    peer_scan += bitCount(match_masks[i][digit]);
                }
            }
            peer_scan += bitCount(match_masks[gl_SubgroupID][digit] & gl_SubgroupLtMask.x);

            constants.dst_buffer.values[spine[digit] + peer_scan] = value;

            if (i != RADIX_ITEMS_PER_INVOCATION - 1) {
                barrier();

                // Increment the spine with the counts for the workgroup we just wrote out.
                for (uint i = 0; i < NUM_SUBGROUPS; i++) {
                    atomicAdd(spine[local_id], bitCount(match_masks[i][local_id]));
                }
            }
        }
    }
}
